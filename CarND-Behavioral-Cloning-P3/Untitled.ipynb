{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\van.vu\\AppData\\Local\\Continuum\\miniconda2\\envs\\IntroToTensorFlow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Flatten, Dense, Lambda, Cropping2D, Convolution2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "image_paths = []\n",
    "measurements = []\n",
    "adjusted_angle = 0.2\n",
    "data_folder = './GoodData/'\n",
    "image_folder = data_folder + 'IMG/'\n",
    "\n",
    "with open(data_folder + 'driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        measurement = float(line[3])\n",
    "\n",
    "        image_paths.append(line[0].split('\\\\')[-1])\n",
    "        measurements.append(measurement)\n",
    "\n",
    "        image_paths.append(line[1].split('\\\\')[-1])\n",
    "        measurements.append(measurement + adjusted_angle)\n",
    "\n",
    "        image_paths.append(line[2].split('\\\\')[-1])\n",
    "        measurements.append(measurement - adjusted_angle)   \n",
    "    \n",
    "X_train = np.array(image_paths)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "## SPLIT TRAIN AND VALID DATA\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n"
     ]
    }
   ],
   "source": [
    "print(len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image,steering):\n",
    "    coin=np.random.randint(0,2)\n",
    "    if coin==0:\n",
    "        image, steering = cv2.flip(image,1), -steering\n",
    "    return image,steering\n",
    "\n",
    "def random_brightness(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = random.uniform(0.3,1.0)    \n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "def crop_and_resize(image):\n",
    "    cropped = cv2.resize(image[60:140,:], (64,64))\n",
    "    return cropped\n",
    "\n",
    "def preprocess_image(image_path,steering, isTrainImage = True):\n",
    "    image = cv2.imread(image_folder + image_path)\n",
    "    cropped_image = crop_and_resize(image) \n",
    "    if isTrainImage:\n",
    "        flip_image, flip_steering = random_flip(cropped_image, steering)\n",
    "        flip_image = random_brightness(flip_image)\n",
    "        return flip_image, flip_steering\n",
    "    else:\n",
    "        return cropped_image, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x /255.0 - 0.5, input_shape=(160,320,3)))\n",
    "    model.add(Cropping2D(cropping=((50,20),(0,0))))\n",
    "    model.add(Convolution2D(24,(5,5),strides=(2,2),activation=\"relu\"))\n",
    "    model.add(Convolution2D(36,(5,5),strides=(2,2),activation=\"relu\"))\n",
    "    model.add(Convolution2D(48,(5,5),strides=(2,2),activation=\"relu\"))\n",
    "    model.add(Convolution2D(64,(3,3),activation=\"relu\"))\n",
    "    model.add(Convolution2D(64,(3,3),activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\van.vu\\AppData\\Local\\Continuum\\miniconda2\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\van.vu\\AppData\\Local\\Continuum\\miniconda2\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., steps_per_epoch=9600, epochs=1, validation_steps=2400)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 7184s 748ms/step - loss: 0.0465 - val_loss: 0.0410\n"
     ]
    }
   ],
   "source": [
    "def generator(X_data, y_data, isTrainImages = True, batch_size=32):\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        images, measurements = shuffle(X_data, y_data)\n",
    "        \n",
    "        batch_images = []\n",
    "        batch_measurements = []\n",
    "        for i in range(batch_size):\n",
    "            choice = int(np.random.choice(len(images),1))\n",
    "            image, measurement = preprocess_image(images[choice], measurements[choice], isTrainImages)\n",
    "            \n",
    "            batch_images.append(image)\n",
    "            batch_measurements.append(measurement)\n",
    "        \n",
    "        yield np.array(batch_images), np.array(batch_measurements)\n",
    "            \n",
    "            \n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(X_train, y_train)\n",
    "validation_generator = generator(X_valid, y_valid, False)\n",
    "\n",
    "model = getModel()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(train_generator, samples_per_epoch= len(X_train), validation_data=validation_generator,\n",
    "                    nb_val_samples=len(X_valid), nb_epoch=1)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images, augmented_measurements = [], []\n",
    "for image, measurement in zip(images, measurements):\n",
    "    #augmented_images.append(image)\n",
    "    #augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    augmented_measurements.append(measurement*-1.0)\n",
    "\n",
    "images.extend(augmented_images)\n",
    "measurements.extend(augmented_measurements)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(measurements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x /255.0 - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((50,20),(0,0))))\n",
    "model.add(Convolution2D(24,(5,5),strides=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(36,(5,5),strides=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(48,(5,5),strides=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(Convolution2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "#model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=3)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
